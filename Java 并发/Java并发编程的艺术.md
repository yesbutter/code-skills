# Java并发编程的艺术

## 1  并发编程的挑战

### 1.1  上下文切换

### 1.2  死锁

### 1.3  资源的挑战

资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。 例如，服务器的带宽只有2Mb/s，某个资源的下载速度是1Mb/s每秒，系统启动10个线程下载资 源，下载速度不会变成10Mb/s，所以在进行并发编程时，要考虑这些资源的限制。硬件资源限 制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度

## 2  Java并发与底层实现原理

### 2.1  volatile

- 2.1.1  实现原理

  有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码
  1）将当前处理器缓存行的数据写回到系统内存。
   2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。

- 2.1.2  使用优化

  Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类LinkedTransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性 能。LinkedTransferQueue的代码如下。
   /** 队列中的头部节点 */ 
  private transient f?inal PaddedAtomicReference head; 
  /** 队列中的尾部节点 */ 
  private transient f?inal PaddedAtomicReference tail; 
  static final class PaddedAtomicReference  extends AtomicReference T> 
  { // 使用很多4个字节的引用追加到64个字节 Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe; PaddedAtomicReference(T r) 
  { super(r); } } 
  public class AtomicReference  implements java.io.Serializable 
  { private volatile V value; 
  // 省略其他代码 
  ｝ 
  LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的 头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类 AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对 象的引用占4个字节，它追加了15个变量（共占60个字节），再加上父类的value变量，一共64个 字节。 为什么追加64字节能够提高并发编程的效率呢？因为对于英特尔酷睿i7、酷睿、Atom和 NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不 支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将 它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一 个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致 其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头 节点和尾节点
  所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使 用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存 行，使头、尾节点在修改时不会互相锁定。

### 2.2  synchronized

·对于普通同步方法，锁是当前实例对象。 ·对于静态同步方法，锁是当前类的Class对象。 ·
对于同步方法块，锁是Synchonized括号里配置的对象。

- 2.2.1   Java对象头

  synchronized用的锁是存在Java对象头里的。

- 2.2.2  锁的升级与对比

  Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在 Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状 态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏 向锁升级成轻量级锁后不能降级成偏向锁。

	- 偏向锁

	  HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同 一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并 获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出 同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否 存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需 要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则 使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。

	- 轻量级锁

	  线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并 将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失 败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。

	- 重量级锁

	  线程竞争不使用自旋，不会消耗CPU，线程阻塞相应时间慢。
	  适用于追求吞吐量，同步执行代码速度较长。

### 2.3  原子操作

原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意 为“不可被中断的一个或一系列操作”。

- 2.3.1  如何实现原子操作

	- 总线锁

	  总线锁就是使用处理器提供的一个 LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该 处理器可以独占共享内存。

	- 缓存锁

	  在同一时刻，我们只需保证对某个内存地址 的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处 理器不能操作其他内存地址的数据。
	  “缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声 言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子 性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处 理器回写已被锁定的缓存行的数据时，会使缓存行无效

- 2.3.2  Java如何实现原子操作

	- 循环CAS

	  JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本 思路就是循环进行CAS操作直到成功为止。

		- ABA问题

		  因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化 则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它 的值没有发生变化，但是实际上却变化了。
		  解决方法：使用版本号。在变量前面 追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。

		- 循环时间长开销大

		  自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如 果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第 一，它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间 取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候 因内存顺序冲突（Memory Order Violation）而引起CPU流水线被清空（CPU Pipeline Flush），从而 提高CPU的执行效率。

		- 只能保证一个共享变量的原子操作。

		  解决方法：把多个共享变量合并成一个共享变量来 操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始， JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对 象里来进行CAS操作。

## 3  Java内存模型

### 3.1  Java内存模型的基础

- 3.1.1  并发编程模型线程通信

	- 共享内存

	  线程之间共享程序的公共状态，通过写-读内存中的公共状态 进行隐式通信。
	  Java的并发采用的是共享内存模型

	- 消息传递

	  线程之间没有公共状态，线程之间必须通过发送消 息来显式进行通信。

- 3.1.2  Java内存模型抽象结构

  在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享。局部变量（Local Variables），方 法定义参数（Java语言规范称之为Formal Method Parameters）和异常处理器参数（Exception Handler Parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影 响。

	- 共享内存

	  1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。
	   2）线程B到主内存中去读取线程A之前已更新过的共享变量。
	  从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要 经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供 内存可见性保证。

- 3.1.3  指令重排

	- 编译器优化的重排序

	  编译器在不改变单线程程序语义的前提下，可以重新安排语句 的执行顺序。

	- 指令级并行的重排序

	  现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应 机器指令的执行顺序。

	- 内存系统的重排序

	  由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上 去可能是在乱序执行。

### 3.2  happens-before

在JMM中，如果一 个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关 系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间

- 程序顺序规则

  一个线程中的每个操作，happens-before于该线程中的任意后续操作。

- 监视器锁规则

  对一个锁的解锁，happens-before于随后对这个锁的加锁。

- volatile变量规则

  ：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。

- start()规则

  如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。

- join()规则

  如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。

- 传递性

  如果A happens-before B，且B happens-before C，那么A happens-before C

### 3.3  实例

- 3.3.1 DCL
- 3.3.2  延迟初始化

  public class InstanceFactory 
  { 
  private static class InstanceHolder 
  { 
  public static Instance instance = new Instance(); 
  } 
  public static Instance getInstance() { return InstanceHolder.instance ; // 这里将导致InstanceHolder类被初始化 
  }
  }

## 4  线程

### 4.1  为什么使用多线程

正确使用多线程，总是能够给开发人员带来显著的好处，而使用多线 程的原因主要有以下几点。

- 更多的处理器核心

  随着处理器上的核心数量越来越多，以及超线程技术的广泛运用，现在大多数计算机都 比以往更加擅长并行计算，而处理器性能的提升方式，也从更高的主频向更多的核心发展。

- 更快的响应时间

  有时我们会编写一些较为复杂的代码（这里的复杂不是说复杂的算法，而是复杂的业务逻 辑）

- 更好的编程模型

  Java为多线程编程提供了良好、考究并且一致的编程模型，使开发人员能够更加专注于问 题的解决，即为所遇到的问题建立合适的模型，而不是绞尽脑汁地考虑如何将其多线程化。一 旦开发人员建立好了模型，稍做修改总是能够方便地映射到Java提供的多线程编程模型上。

### 4.2  线程间通信

- 4.2.1  共享内存

  Java支持多个线程同时访问一个对象或者对象的成员变量，由于每个线程可以拥有这个 变量的拷贝（虽然对象以及成员变量分配的内存是在共享内存中的，但是每个执行的线程还是 可以拥有一份拷贝，这样做的目的是加速程序的执行，这是现代多核处理器的一个显著特 性）

	- volatile

	  关键字volatile可以用来修饰字段（成员变量），就是告知程序任何对该变量的访问均需要 从共享内存中获取，而对它的改变必须同步刷新回共享内存，它能保证所有线程对变量访问 的可见性。

	- synchronized

	  关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程 在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性 和排他性。

- 4.2.2  等待/通知机制

  一个线程修改了一个对象的值，而另一个线程感知到了变化，然后进行相应的操作，整个 过程开始于一个线程，而最终执行又是另一个线程。前者是生产者，后者就是消费者，这种模 式隔离了“做什么”（what）和“怎么做”（How）

	- wait/notify
	- 管道输入/输出流

### 4.3  线程应用

- 4.3.1  等待超时

	- 问题

	  开发人员经常会遇到这样的方法调用场景：调用一个方法时等待一段时间（一般来说是给 定一个时间段），如果该方法能够在给定的时间段之内得到结果，那么将结果立刻返回，反之， 超时返回默认结果。

	- 实现

	  这时仅需要wait(REMAINING)即可，在wait(REMAINING)返回之后会将执行： REMAINING=FUTURE–now。如果REMAINING小于等于0，表示已经超时，直接退出，否则将 继续执行wait(REMAINING)。

- 4.3.2  线程池技术

  线程池的本质就是使用了一个线程安全的工作队列连接工作者线程和客户端 线程，客户端线程将任务放入工作队列后便返回，而工作者线程则不断地从工作队列上取出 工作并执行。当工作队列为空时，所有的工作者线程均等待在工作队列上，当有客户端提交了 一个任务之后会通知任意一个工作者线程，随着大量的任务被提交，更多的工作者线程会被 唤醒。

	- 问题

	  对于服务端的程序，经常面对的是客户端传入的短小（执行时间短、工作内容较为单一） 任务，需要服务端快速处理并返回结果。如果服务端每次接受到一个任务，创建一个线程，然 后进行执行，这在原型阶段是个不错的选择，但是面对成千上万的任务递交进服务器时，如果 还是采用一个任务一个线程的方式，那么将会创建数以万记的线程，这不是一个好的选择。因 为这会使操作系统频繁的进行线程上下文切换，无故增加系统的负载，而线程的创建和消亡 都是需要耗费系统资源的，也无疑浪费了系统资源。

	- 实现

	  线程池技术能够很好地解决这个问题，它预先创建了若干数量的线程，并且不能由用户 直接对线程的创建进行控制，在这个前提下重复使用固定或较为固定数目的线程来完成任务 的执行。这样做的好处是，一方面，消除了频繁创建和消亡线程的系统资源开销，另一方面， 面对过量任务的提交能够平缓的劣化。

## 5  锁

### 5.1  Lock接口

它提供了与synchronized关键字类似的同步功 能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提 供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以 及超时获取锁等多种synchronized关键字所不具备的同步特性。

### 5.2  队列同步器(AQS)

队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组 件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获 取线程的排队工作.

同步器面向的是锁的实现者， 它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同 步器很好地隔离了使用者和实现者所需关注的领域。

### 5.3  重入锁

### 5.4  读写锁

### 5.5  LockSupport

### 5.6  Condition接口

## 6  并发容器和框架

